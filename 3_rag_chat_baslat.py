import gradio as gr
import torch
from transformers import pipeline
from langchain_community.llms import HuggingFacePipeline
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
import sys

# --- 1. AYARLAR ---
print("ğŸš€ Sistem TinyLlama ile baÅŸlatÄ±lÄ±yor... (%100 TÃ¼rkÃ§e Modu)")

model_id = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

pipe = pipeline(
    "text-generation",
    model=model_id,
    torch_dtype=torch.float32,
    device_map="auto",
    max_new_tokens=256,
    do_sample=True,
    # SICAKLIK AYARI Ã‡OK Ã–NEMLÄ°:
    # 0.1 yaptÄ±k ki hayal kurmasÄ±n, sadece metni okusun.
    temperature=0.1,          
    top_p=0.90,
    repetition_penalty=1.2
)
llm = HuggingFacePipeline(pipeline=pipe)

# TÃ¼rkÃ§e iÃ§in en iyi embedding modeli
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# --- 2. HAFIZA KONTROLÃœ ---
print("ğŸ“š HafÄ±za yÃ¼kleniyor...")
if not os.path.exists("alzheimer_veri.txt"):
    print("âŒ HATA: 'alzheimer_veri.txt' dosyasÄ± bulunamadÄ±!")
    print("LÃ¼tfen Ã¶nce 1_veri_olustur.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak veriyi oluÅŸturun.")
    sys.exit()

loader = TextLoader("alzheimer_veri.txt", encoding="utf-8")
docs = loader.load()

# Metni daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼yoruz ki odaklanabilsin
text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)
parcalar = text_splitter.split_documents(docs)

vector_store = FAISS.from_documents(parcalar, embedding_model)
print("âœ… HafÄ±za hazÄ±r!")

# --- 3. TÃœRKÃ‡E PROMPT (KOMUT) ---
# TinyLlama'ya TÃ¼rkÃ§e emir veriyoruz ama <|system|> etiketleri ile ciddiyet katÄ±yoruz.
template = """<|system|>
Sen sadece aÅŸaÄŸÄ±daki METÄ°N iÃ§indeki bilgileri kullanan bir asistansÄ±n.
DÄ±ÅŸarÄ±dan bilgi ekleme. Uydurma yapma.
Soruyu sadece METÄ°N'e bakarak TÃœRKÃ‡E cevapla.

METÄ°N:
{context}
</s>
<|user|>
SORU: {question}
</s>
<|assistant|>
"""

PROMPT = PromptTemplate(template=template, input_variables=["context", "question"])

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    # k=2 yaptÄ±k. En alakalÄ± 2 parÃ§ayÄ± getirsin.
    retriever=vector_store.as_retriever(search_kwargs={"k": 2}),
    chain_type_kwargs={"prompt": PROMPT}
)

# --- 4. CEVAP TEMÄ°ZLEME MOTORU ---
def cevapla(soru):
    if not soru:
        return ""
    
    # 1. CevabÄ± Ã¼ret
    ham_cevap = qa_chain.invoke({"query": soru})
    metin = ham_cevap["result"]
    
    # 2. Teknik etiketleri temizle (<|assistant|> vb.)
    if "<|assistant|>" in metin:
        temiz_cevap = metin.split("<|assistant|>")[-1]
    else:
        temiz_cevap = metin

    # 3. Ä°NGÄ°LÄ°ZCE FÄ°LTRESÄ° (EÄŸer Ä°ngilizce baÅŸlarsa uyar)
    if "The provided text" in temiz_cevap or "Sure!" in temiz_cevap:
        return "âš ï¸ Model Ä°ngilizce cevap vermeye Ã§alÄ±ÅŸtÄ±. LÃ¼tfen soruyu biraz daha farklÄ± sorabilir misiniz?"

    # 4. Gereksiz baÅŸlÄ±klarÄ± kes (Model bazen metindeki diÄŸer baÅŸlÄ±klarÄ± da okur)
    kesilecekler = ["BÃ–LÃœM", "Soru:", "BAÅLIK:", "TanÄ±m:"]
    for kelime in kesilecekler:
        # EÄŸer cevap Ã§ok kÄ±saysa (10 karakterden az) kesme, belki cevap o kelimeyle baÅŸlÄ±yordur.
        if kelime in temiz_cevap and len(temiz_cevap) > 50: 
             # Kelimenin geÃ§tiÄŸi yerden sonrasÄ±nÄ± at
             parca = temiz_cevap.split(kelime)
             if len(parca[0]) > 5: # EÄŸer ilk parÃ§a mantÄ±klÄ±ysa onu al
                 temiz_cevap = parca[0]

    return temiz_cevap.strip()

# --- 5. ARAYÃœZ ---
arayuz = gr.Interface(
    fn=cevapla,
    inputs=gr.Textbox(lines=2, placeholder="Ã–rn: Annem banyo yapmak istemiyor, ne yapmalÄ±yÄ±m?"),
    outputs=gr.Textbox(label="Cevap"),
    title="ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e RAG AsistanÄ± (TinyLlama)",
    description="Sadece yÃ¼klenen TÃ¼rkÃ§e veriyi kullanarak cevap verir."
)

if __name__ == "__main__":
    # TarayÄ±cÄ±da otomatik aÃ§Ä±lmasÄ± iÃ§in inbrowser=True ekledik
    arayuz.launch(inbrowser=True)
