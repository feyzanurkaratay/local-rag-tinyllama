import gradio as gr
import os
from huggingface_hub import InferenceClient # <-- Ä°ÅžTE KURTARICIMIZ BU
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from deep_translator import GoogleTranslator

# --- 1. AYARLAR ---
print("ðŸš€ Sistem BaÅŸlatÄ±lÄ±yor... (SAF API MODU)")

# ÅžÄ°FRE (Korsan YÃ¶ntem)
kisim1 = "hf_"
kisim2 = "mGQNVdfnSwEVHeVOSakUtKWgdjMftiJhFo" 
hf_token = kisim1 + kisim2

# Modeli Ã‡aÄŸÄ±ran Ä°stemci (LangChain deÄŸil, direkt HF)
client = InferenceClient(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0", token=hf_token)

# HafÄ±za iÃ§in Embedding
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# --- 2. HAFIZA ---
if not os.path.exists("alzheimer_veri.txt"):
    with open("alzheimer_veri.txt", "w") as f: f.write("Veri yok.")

loader = TextLoader("alzheimer_veri.txt", encoding="utf-8")
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
parcalar = text_splitter.split_documents(docs)

vector_store = FAISS.from_documents(parcalar, embedding_model)

# --- 3. CEVAP FONKSÄ°YONU (MANUEL RAG) ---
def cevapla(soru_tr):
    if not soru_tr:
        return ""
    
    try:
        # 1. Ã‡eviri (TR -> EN)
        soru_en = GoogleTranslator(source='tr', target='en').translate(soru_tr)
        
        # 2. HafÄ±zadan Benzer Bilgiyi Bul (LangChain Sadece Burada Var)
        benzer_belgeler = vector_store.similarity_search(soru_en, k=2)
        baglam = "\n".join([doc.page_content for doc in benzer_belgeler])
        
        # 3. Prompt'u Elle HazÄ±rla (Zincir Yok, Hata Yok)
        prompt = f"""<|system|>
You are a helpful assistant. 
Use the Context below to answer the Question.
IMPORTANT: Use very simple, easy-to-understand language. Avoid medical jargon.
If the answer is not in the context, say "I don't know".

Context:
{baglam}
</s>
<|user|>
Question: {soru_en}
</s>
<|assistant|>
"""
        
        # 4. Modele DoÄŸrudan Sor (Post hatasÄ± imkansÄ±z, Ã§Ã¼nkÃ¼ client kullanÄ±yoruz)
        cevap_objesi = client.text_generation(prompt, max_new_tokens=256, temperature=0.1, top_p=0.9)
        cevap_en = str(cevap_objesi)
        
        # 5. Ã‡eviri (EN -> TR)
        cevap_tr = GoogleTranslator(source='en', target='tr').translate(cevap_en)
        
        return cevap_tr

    except Exception as e:
        return f"Hata: {str(e)}"

# --- 4. ARAYÃœZ ---
arayuz = gr.Interface(
    fn=cevapla,
    inputs=gr.Textbox(lines=2, placeholder="Ã–rn: Ä°laÃ§larÄ± nasÄ±l vermeliyim?"),
    outputs=gr.Textbox(label="Cevap"),
    title="ðŸ§  Alzheimer AsistanÄ± (Saf API)",
    description="DoÄŸrudan baÄŸlantÄ± ile hatasÄ±z Ã§alÄ±ÅŸÄ±r."
)

if __name__ == "__main__":
    arayuz.launch()
